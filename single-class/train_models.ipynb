{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5feda89b",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd54317f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "import timeit\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from statsmodels.stats.contingency_tables import mcnemar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c142f6",
   "metadata": {},
   "source": [
    "#### Check if CUDA is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "027d7ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdf125e",
   "metadata": {},
   "source": [
    "## Define NN class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7be83e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MolecularPropertyPrediction(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MolecularPropertyPrediction, self).__init__()\n",
    "        self.embed_atom = nn.Embedding(n_fingerprint, dim)\n",
    "        self.W_atom = nn.ModuleList([nn.Linear(dim, dim) for _ in range(layer)])\n",
    "        self.W_property = nn.Linear(dim+extra_dim, 11)\n",
    "    \n",
    "    \"\"\"Pad adjacency matrices for batch processing.\"\"\"\n",
    "    def pad(self, matrices, value):\n",
    "        sizes = [d.shape[0] for d in matrices]\n",
    "        D = sum(sizes)\n",
    "        pad_matrices = value + np.zeros((D, D))\n",
    "        m = 0\n",
    "        for i, d in enumerate(matrices):\n",
    "            s_i = sizes[i]\n",
    "            pad_matrices[m:m+s_i, m:m+s_i] = d\n",
    "            m += s_i\n",
    "        return torch.FloatTensor(pad_matrices).to(device)\n",
    "    \n",
    "    def sum_axis(self, xs, axis):\n",
    "        y = list(map(lambda x: torch.sum(x, 0), torch.split(xs, axis)))\n",
    "        return torch.stack(y)\n",
    "    \n",
    "    def update(self, xs, adjacency, i):\n",
    "        hs = torch.relu(self.W_atom[i](xs))\n",
    "        return torch.matmul(adjacency, hs)\n",
    "    \n",
    "    def forward(self, inputs, sel_maccs):\n",
    "        \n",
    "        atoms, adjacency = inputs\n",
    "        axis = list(map(lambda x: len(x), atoms))\n",
    "\n",
    "        atoms = torch.cat(atoms)\n",
    "        x_atoms = self.embed_atom(atoms)\n",
    "        adjacency = self.pad(adjacency, 0)\n",
    "\n",
    "        for i in range(layer):\n",
    "            x_atoms = self.update(x_atoms, adjacency, i)\n",
    "        \n",
    "        extra_inputs = sel_maccs.to(device)\n",
    "        y_molecules = self.sum_axis(x_atoms, axis)\n",
    "        \n",
    "        #AM: Enable this if we want extra_inputs.\n",
    "        y_molecules = torch.cat((y_molecules,extra_inputs),1)\n",
    "        z_properties = self.W_property(y_molecules)\n",
    "        \n",
    "        return z_properties\n",
    "    \n",
    "    def embed_inputs(self, inputs, sel_maccs):\n",
    "        atoms, adjacency = inputs\n",
    "        axis = list(map(lambda x: len(x), atoms))\n",
    "\n",
    "        atoms = torch.cat(atoms)\n",
    "        x_atoms = self.embed_atom(atoms)\n",
    "        adjacency = self.pad(adjacency, 0)\n",
    "\n",
    "        for i in range(layer):\n",
    "            x_atoms = self.update(x_atoms, adjacency, i)\n",
    "        \n",
    "        extra_inputs = sel_maccs.to(device)\n",
    "        y_molecules = self.sum_axis(x_atoms, axis)\n",
    "        \n",
    "        y_molecules = torch.cat((y_molecules,extra_inputs),1)\n",
    "        return(y_molecules)    \n",
    "    \n",
    "    \n",
    "    def __call__(self, data_batch, train=True, correlation_analysis=False):\n",
    "        \n",
    "        sel_maccs = torch.FloatTensor(data_batch[-1])\n",
    "        \n",
    "        inputs, t_properties = data_batch[:-2], torch.cat(data_batch[-2])\n",
    "        \n",
    "        if correlation_analysis:\n",
    "            embedding = self.embed_inputs(inputs, sel_maccs)\n",
    "            return(embedding)\n",
    "        \n",
    "        z_properties = self.forward(inputs, sel_maccs)\n",
    "        \n",
    "        if train:\n",
    "            loss = F.cross_entropy(z_properties, t_properties)\n",
    "            return loss\n",
    "        else:\n",
    "            zs = F.softmax(z_properties, 1).to('cpu').data.numpy()\n",
    "            ts = t_properties.to('cpu').data.numpy()\n",
    "            scores = list(map(lambda x: x.argsort()[-3:][::-1], zs))\n",
    "            labels = list(map(lambda x: np.argmax(x), zs))\n",
    "            return scores, labels, ts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e007f273",
   "metadata": {},
   "source": [
    "#### Create trainer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "315aac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "        \n",
    "    def train(self, dataset_train):\n",
    "        np.random.shuffle(dataset_train)\n",
    "        N = len(dataset_train)\n",
    "        loss_total = 0\n",
    "        for i in range(0, N, batch):\n",
    "            data_batch = list(zip(*dataset_train[i:i+batch]))\n",
    "            loss = self.model(data_batch)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            loss_total += loss.to('cpu').data.numpy()\n",
    "        return loss_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2815db07",
   "metadata": {},
   "source": [
    "#### Create tester class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34427674",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tester(object):\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def test(self, dataset_test):\n",
    "\n",
    "        N = len(dataset_test)\n",
    "        score_list, label_list, t_list = [], [], []\n",
    "\n",
    "        for i in range(0, N, batch):\n",
    "            data_batch = list(zip(*dataset_test[i:i+batch]))\n",
    "            scores, labels, ts = self.model(data_batch, train=False)\n",
    "            score_list = np.append(score_list, scores)\n",
    "            label_list = np.append(label_list, labels)\n",
    "            t_list = np.append(t_list, ts)\n",
    "        \n",
    "        neg_pos_list1 = []\n",
    "        neg_pos_list2 = []\n",
    "        neg_pos_list3 = []\n",
    "        auc = accuracy_score(t_list, label_list)\n",
    "        \n",
    "        auc2, auc3 = 0, 0 \n",
    "        for i in range(0, N):\n",
    "            true_class = t_list[i]\n",
    "            \n",
    "            if true_class == score_list[3*i]:\n",
    "                neg_pos_list1.append(1)\n",
    "            else:\n",
    "                neg_pos_list1.append(0)\n",
    "            \n",
    "            if true_class in score_list[3*i:3*i+2]:\n",
    "                auc2 += 1\n",
    "                neg_pos_list2.append(1)\n",
    "            else:\n",
    "                neg_pos_list2.append(0)\n",
    "                \n",
    "            if true_class in score_list[3*i:3*i+3]:\n",
    "                auc3 += 1\n",
    "                neg_pos_list3.append(1)\n",
    "            else:\n",
    "                neg_pos_list3.append(0)\n",
    "\n",
    "        return auc, auc2/N, auc3/N, neg_pos_list1, neg_pos_list2, neg_pos_list3\n",
    "    \n",
    "    def result(self, epoch, time, loss, auc_dev,\n",
    "               auc_test, file_result):\n",
    "        with open(file_result, 'a') as f:\n",
    "            result = map(str, [epoch, time, loss, auc_dev, auc_test])\n",
    "            f.write('\\t'.join(result) + '\\n')\n",
    "\n",
    "    def save_model(self, model, file_name):\n",
    "        torch.save(model, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09b222f",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a308bfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tensor(file_name, dtype):\n",
    "    return [dtype(d).to(device) for d in np.load(file_name + '.npy', allow_pickle=True)]\n",
    "\n",
    "\n",
    "def load_numpy(file_name):\n",
    "    return np.load(file_name + '.npy', allow_pickle=True)\n",
    "\n",
    "\n",
    "def load_pickle(file_name):\n",
    "    with open(file_name, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def shuffle_dataset(dataset, seed):\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(dataset)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def split_dataset(dataset, ratio):\n",
    "    n = int(ratio * len(dataset))\n",
    "    dataset_1, dataset_2 = dataset[:n], dataset[n:]\n",
    "    return dataset_1, dataset_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14959df",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2df44dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "radius         = 2\n",
    "dim            = 50\n",
    "layer          = 2\n",
    "batch          = 10\n",
    "lr             = 1e-3\n",
    "lr_decay       = 0.5\n",
    "decay_interval = 10\n",
    "iteration      = 100\n",
    "extra_dim      = 20\n",
    "\n",
    "(dim, layer, batch, decay_interval, iteration, extra_dim) = map(int, [dim, layer, batch, decay_interval, iteration, extra_dim])\n",
    "lr, lr_decay = map(float, [lr, lr_decay])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d5d3b5",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "800bf54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_input = ('inputgcn'+str(radius)+'/')\n",
    "\n",
    "molecules    = load_tensor(dir_input + 'molecules', torch.LongTensor)\n",
    "adjacencies  = load_numpy(dir_input + 'adjacencies')\n",
    "t_properties = load_tensor(dir_input + 'properties', torch.LongTensor)\n",
    "maccs        = load_numpy(dir_input + 'maccs')\n",
    "\n",
    "with open(dir_input + 'fingerprint_dict.pickle', 'rb') as f:\n",
    "    fingerprint_dict = pickle.load(f)\n",
    "    unknown          = 100\n",
    "    n_fingerprint    = len(fingerprint_dict) + unknown\n",
    "    \n",
    "dataset = list(zip(molecules, adjacencies, t_properties, maccs))\n",
    "dataset = shuffle_dataset(dataset, 1234)\n",
    "dataset_train, dataset_   = split_dataset(dataset, 0.8)\n",
    "dataset_dev, dataset_test = split_dataset(dataset_, 0.5)\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "model   = MolecularPropertyPrediction().to(device)\n",
    "trainer = Trainer(model)\n",
    "tester  = Tester(model)\n",
    "\n",
    "dir_output = ('output/')\n",
    "os.makedirs(dir_output, exist_ok=True)\n",
    "\n",
    "dir_result = ('output/result/')\n",
    "os.makedirs(dir_result, exist_ok=True)\n",
    "\n",
    "dir_model  = ('output/model/')\n",
    "os.makedirs(dir_model, exist_ok=True)\n",
    "\n",
    "file_result = dir_result + '.txt'\n",
    "with open(file_result, 'w') as f:\n",
    "    f.write('Epoch\\tTime(sec)\\tLoss_train\\tAUC_dev\\tAUC_test\\n')\n",
    "\n",
    "file_model = dir_model + 'model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b42acf61",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch \t Time(sec) \t Loss_train \t AUC_dev \t AUC2_dev \t AUC3_dev \t AUC_test \t AUC2_test \t AUC3_test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mayan\\AppData\\Local\\Temp\\ipykernel_18628\\647757525.py:73: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:210.)\n",
      "  sel_maccs = torch.FloatTensor(data_batch[-1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t 8.5518 \t 538.8387 \t 0.5947 \t 0.7357 \t 0.8194 \t 0.6872 \t 0.7930 \t 0.8590\n",
      "1 \t 9.9744 \t 335.4248 \t 0.6762 \t 0.7996 \t 0.8789 \t 0.7423 \t 0.8480 \t 0.9317\n",
      "2 \t 11.4728 \t 265.0929 \t 0.7467 \t 0.8568 \t 0.8987 \t 0.7863 \t 0.8965 \t 0.9383\n",
      "3 \t 12.9603 \t 211.1913 \t 0.7357 \t 0.8612 \t 0.9075 \t 0.7731 \t 0.8811 \t 0.9405\n",
      "4 \t 14.6474 \t 172.1952 \t 0.7974 \t 0.8767 \t 0.9229 \t 0.8370 \t 0.9273 \t 0.9648\n",
      "5 \t 16.4042 \t 145.3180 \t 0.8084 \t 0.8833 \t 0.9207 \t 0.8282 \t 0.9295 \t 0.9626\n",
      "6 \t 18.0658 \t 125.2414 \t 0.8172 \t 0.8965 \t 0.9251 \t 0.8370 \t 0.9449 \t 0.9714\n",
      "7 \t 19.7409 \t 110.7273 \t 0.8062 \t 0.8899 \t 0.9273 \t 0.8502 \t 0.9405 \t 0.9670\n",
      "8 \t 21.4575 \t 91.8339 \t 0.8304 \t 0.9009 \t 0.9295 \t 0.8590 \t 0.9471 \t 0.9670\n",
      "9 \t 23.1285 \t 67.8698 \t 0.8414 \t 0.8987 \t 0.9295 \t 0.8700 \t 0.9493 \t 0.9736\n",
      "10 \t 24.9020 \t 61.4977 \t 0.8238 \t 0.9009 \t 0.9405 \t 0.8700 \t 0.9471 \t 0.9692\n",
      "11 \t 26.8341 \t 57.9448 \t 0.8128 \t 0.8987 \t 0.9207 \t 0.8546 \t 0.9251 \t 0.9692\n",
      "12 \t 28.8838 \t 55.7639 \t 0.8348 \t 0.9053 \t 0.9383 \t 0.8833 \t 0.9493 \t 0.9736\n",
      "13 \t 30.8430 \t 56.0510 \t 0.8458 \t 0.9097 \t 0.9383 \t 0.8855 \t 0.9581 \t 0.9780\n",
      "14 \t 32.8556 \t 46.7289 \t 0.8392 \t 0.9075 \t 0.9317 \t 0.8767 \t 0.9405 \t 0.9692\n",
      "15 \t 34.8639 \t 42.2319 \t 0.8480 \t 0.9163 \t 0.9471 \t 0.8789 \t 0.9537 \t 0.9736\n",
      "16 \t 36.7167 \t 40.1491 \t 0.8392 \t 0.9185 \t 0.9471 \t 0.8899 \t 0.9581 \t 0.9780\n",
      "17 \t 38.4417 \t 38.7084 \t 0.8392 \t 0.9097 \t 0.9405 \t 0.8811 \t 0.9537 \t 0.9736\n",
      "18 \t 40.1275 \t 35.9886 \t 0.8282 \t 0.9031 \t 0.9383 \t 0.8789 \t 0.9537 \t 0.9714\n",
      "19 \t 41.8871 \t 26.7930 \t 0.8348 \t 0.9075 \t 0.9449 \t 0.8943 \t 0.9449 \t 0.9758\n",
      "20 \t 43.6098 \t 26.2134 \t 0.8392 \t 0.9097 \t 0.9405 \t 0.8789 \t 0.9493 \t 0.9736\n",
      "21 \t 45.3437 \t 25.0184 \t 0.8216 \t 0.9141 \t 0.9449 \t 0.8811 \t 0.9559 \t 0.9736\n",
      "22 \t 47.0875 \t 22.4761 \t 0.8370 \t 0.9097 \t 0.9427 \t 0.8877 \t 0.9604 \t 0.9736\n",
      "23 \t 48.8101 \t 21.5716 \t 0.8458 \t 0.9097 \t 0.9493 \t 0.8855 \t 0.9515 \t 0.9758\n",
      "24 \t 50.5622 \t 21.6060 \t 0.8348 \t 0.9097 \t 0.9471 \t 0.8855 \t 0.9559 \t 0.9780\n",
      "25 \t 52.2381 \t 19.6732 \t 0.8436 \t 0.9119 \t 0.9471 \t 0.8943 \t 0.9537 \t 0.9736\n",
      "26 \t 53.9067 \t 20.2153 \t 0.8436 \t 0.9163 \t 0.9427 \t 0.8943 \t 0.9626 \t 0.9736\n",
      "27 \t 55.8095 \t 18.6638 \t 0.8502 \t 0.9097 \t 0.9449 \t 0.8921 \t 0.9604 \t 0.9736\n",
      "28 \t 57.6632 \t 17.1652 \t 0.8546 \t 0.9075 \t 0.9449 \t 0.8877 \t 0.9537 \t 0.9714\n",
      "29 \t 59.5159 \t 15.0092 \t 0.8568 \t 0.9119 \t 0.9449 \t 0.9009 \t 0.9559 \t 0.9758\n",
      "30 \t 61.5862 \t 14.4311 \t 0.8590 \t 0.9141 \t 0.9449 \t 0.8855 \t 0.9493 \t 0.9736\n",
      "31 \t 63.4034 \t 13.9219 \t 0.8546 \t 0.9141 \t 0.9493 \t 0.8943 \t 0.9581 \t 0.9758\n",
      "32 \t 65.1692 \t 14.7082 \t 0.8524 \t 0.9163 \t 0.9471 \t 0.8965 \t 0.9537 \t 0.9736\n",
      "33 \t 66.9932 \t 14.0306 \t 0.8524 \t 0.9163 \t 0.9449 \t 0.8899 \t 0.9537 \t 0.9736\n",
      "34 \t 68.6987 \t 13.3936 \t 0.8546 \t 0.9141 \t 0.9449 \t 0.9009 \t 0.9515 \t 0.9736\n",
      "35 \t 70.5227 \t 12.7786 \t 0.8524 \t 0.9141 \t 0.9427 \t 0.8943 \t 0.9515 \t 0.9758\n",
      "36 \t 72.2728 \t 12.5922 \t 0.8480 \t 0.9185 \t 0.9449 \t 0.8965 \t 0.9559 \t 0.9736\n",
      "37 \t 74.3172 \t 12.0691 \t 0.8524 \t 0.9163 \t 0.9405 \t 0.8943 \t 0.9493 \t 0.9758\n",
      "38 \t 76.2848 \t 13.8967 \t 0.8524 \t 0.9141 \t 0.9405 \t 0.8921 \t 0.9515 \t 0.9758\n",
      "39 \t 78.1471 \t 11.7422 \t 0.8524 \t 0.9163 \t 0.9427 \t 0.8921 \t 0.9493 \t 0.9736\n",
      "40 \t 80.0085 \t 10.2788 \t 0.8524 \t 0.9163 \t 0.9405 \t 0.8987 \t 0.9559 \t 0.9736\n",
      "41 \t 81.8310 \t 10.0135 \t 0.8480 \t 0.9097 \t 0.9361 \t 0.8987 \t 0.9515 \t 0.9758\n",
      "42 \t 83.8567 \t 10.2012 \t 0.8524 \t 0.9141 \t 0.9383 \t 0.9009 \t 0.9493 \t 0.9758\n",
      "43 \t 85.8734 \t 9.8456 \t 0.8502 \t 0.9141 \t 0.9405 \t 0.9009 \t 0.9471 \t 0.9736\n",
      "44 \t 87.9175 \t 9.5972 \t 0.8546 \t 0.9141 \t 0.9405 \t 0.8921 \t 0.9493 \t 0.9714\n",
      "45 \t 89.8299 \t 9.6875 \t 0.8546 \t 0.9141 \t 0.9383 \t 0.8987 \t 0.9537 \t 0.9736\n",
      "46 \t 91.7409 \t 9.5688 \t 0.8546 \t 0.9163 \t 0.9383 \t 0.8943 \t 0.9493 \t 0.9736\n",
      "47 \t 93.6176 \t 9.5858 \t 0.8524 \t 0.9163 \t 0.9383 \t 0.9009 \t 0.9581 \t 0.9758\n",
      "48 \t 95.5021 \t 9.2634 \t 0.8524 \t 0.9163 \t 0.9405 \t 0.8921 \t 0.9537 \t 0.9736\n",
      "49 \t 97.4206 \t 8.7465 \t 0.8568 \t 0.9163 \t 0.9405 \t 0.8921 \t 0.9537 \t 0.9736\n",
      "50 \t 99.2273 \t 8.5847 \t 0.8568 \t 0.9141 \t 0.9405 \t 0.8921 \t 0.9493 \t 0.9736\n",
      "51 \t 101.2731 \t 8.5395 \t 0.8502 \t 0.9119 \t 0.9383 \t 0.8965 \t 0.9515 \t 0.9758\n",
      "52 \t 103.3284 \t 8.4841 \t 0.8524 \t 0.9141 \t 0.9405 \t 0.9009 \t 0.9537 \t 0.9758\n",
      "53 \t 105.2959 \t 8.3913 \t 0.8546 \t 0.9141 \t 0.9361 \t 0.8943 \t 0.9493 \t 0.9714\n",
      "54 \t 107.0990 \t 8.2929 \t 0.8502 \t 0.9163 \t 0.9383 \t 0.9009 \t 0.9559 \t 0.9736\n",
      "55 \t 108.8391 \t 8.3464 \t 0.8524 \t 0.9141 \t 0.9383 \t 0.9053 \t 0.9559 \t 0.9758\n",
      "56 \t 110.6402 \t 8.1317 \t 0.8546 \t 0.9141 \t 0.9361 \t 0.8943 \t 0.9537 \t 0.9736\n",
      "57 \t 112.3919 \t 8.1535 \t 0.8546 \t 0.9141 \t 0.9361 \t 0.8965 \t 0.9515 \t 0.9714\n",
      "58 \t 114.1598 \t 8.0635 \t 0.8546 \t 0.9141 \t 0.9361 \t 0.9031 \t 0.9559 \t 0.9736\n",
      "59 \t 116.0924 \t 7.8117 \t 0.8546 \t 0.9141 \t 0.9383 \t 0.9031 \t 0.9537 \t 0.9736\n",
      "60 \t 117.9784 \t 7.7494 \t 0.8524 \t 0.9141 \t 0.9383 \t 0.9009 \t 0.9537 \t 0.9714\n",
      "61 \t 119.7854 \t 7.7296 \t 0.8546 \t 0.9141 \t 0.9383 \t 0.9031 \t 0.9537 \t 0.9714\n",
      "62 \t 121.8437 \t 7.6574 \t 0.8568 \t 0.9141 \t 0.9383 \t 0.9031 \t 0.9537 \t 0.9736\n",
      "63 \t 123.5813 \t 7.6281 \t 0.8524 \t 0.9141 \t 0.9383 \t 0.8965 \t 0.9537 \t 0.9714\n",
      "64 \t 125.4204 \t 7.5795 \t 0.8546 \t 0.9141 \t 0.9383 \t 0.9009 \t 0.9515 \t 0.9714\n",
      "65 \t 127.4191 \t 7.5511 \t 0.8546 \t 0.9141 \t 0.9383 \t 0.9009 \t 0.9537 \t 0.9714\n",
      "66 \t 129.2242 \t 7.5321 \t 0.8524 \t 0.9141 \t 0.9383 \t 0.9009 \t 0.9537 \t 0.9714\n",
      "67 \t 131.1015 \t 7.5398 \t 0.8590 \t 0.9141 \t 0.9383 \t 0.9009 \t 0.9537 \t 0.9714\n",
      "68 \t 132.8157 \t 7.4643 \t 0.8612 \t 0.9141 \t 0.9383 \t 0.9009 \t 0.9537 \t 0.9736\n",
      "69 \t 134.5890 \t 7.3116 \t 0.8546 \t 0.9141 \t 0.9383 \t 0.9009 \t 0.9537 \t 0.9714\n",
      "70 \t 136.7076 \t 7.3136 \t 0.8568 \t 0.9141 \t 0.9383 \t 0.9031 \t 0.9537 \t 0.9736\n",
      "71 \t 138.4812 \t 7.2714 \t 0.8590 \t 0.9141 \t 0.9383 \t 0.9009 \t 0.9537 \t 0.9736\n",
      "72 \t 140.2939 \t 7.2509 \t 0.8590 \t 0.9141 \t 0.9383 \t 0.9009 \t 0.9537 \t 0.9736\n",
      "73 \t 142.0496 \t 7.2251 \t 0.8590 \t 0.9141 \t 0.9383 \t 0.9031 \t 0.9537 \t 0.9736\n",
      "74 \t 144.0618 \t 7.2157 \t 0.8590 \t 0.9141 \t 0.9383 \t 0.9031 \t 0.9537 \t 0.9736\n",
      "75 \t 145.9717 \t 7.2309 \t 0.8590 \t 0.9141 \t 0.9383 \t 0.9009 \t 0.9537 \t 0.9736\n",
      "76 \t 147.8965 \t 7.1964 \t 0.8590 \t 0.9141 \t 0.9383 \t 0.9009 \t 0.9537 \t 0.9736\n",
      "77 \t 149.7795 \t 7.1668 \t 0.8590 \t 0.9141 \t 0.9383 \t 0.9009 \t 0.9537 \t 0.9736\n",
      "78 \t 151.6121 \t 7.1571 \t 0.8590 \t 0.9141 \t 0.9383 \t 0.9009 \t 0.9537 \t 0.9736\n",
      "79 \t 153.5677 \t 7.0653 \t 0.8590 \t 0.9141 \t 0.9383 \t 0.9009 \t 0.9537 \t 0.9736\n",
      "80 \t 155.4122 \t 7.0614 \t 0.8590 \t 0.9141 \t 0.9383 \t 0.9009 \t 0.9537 \t 0.9736\n",
      "81 \t 157.1754 \t 7.0490 \t 0.8590 \t 0.9141 \t 0.9383 \t 0.9009 \t 0.9537 \t 0.9736\n",
      "82 \t 158.8973 \t 7.0457 \t 0.8568 \t 0.9141 \t 0.9383 \t 0.9009 \t 0.9537 \t 0.9736\n",
      "83 \t 160.9113 \t 7.0332 \t 0.8590 \t 0.9141 \t 0.9383 \t 0.9009 \t 0.9537 \t 0.9736\n",
      "84 \t 162.6702 \t 7.0224 \t 0.8568 \t 0.9141 \t 0.9383 \t 0.9009 \t 0.9537 \t 0.9736\n",
      "85 \t 164.5001 \t 7.0165 \t 0.8590 \t 0.9141 \t 0.9383 \t 0.9009 \t 0.9537 \t 0.9736\n",
      "86 \t 166.4730 \t 7.0143 \t 0.8590 \t 0.9141 \t 0.9383 \t 0.9009 \t 0.9537 \t 0.9736\n",
      "87 \t 168.5164 \t 6.9960 \t 0.8590 \t 0.9141 \t 0.9383 \t 0.9009 \t 0.9537 \t 0.9736\n",
      "88 \t 170.5544 \t 6.9893 \t 0.8590 \t 0.9141 \t 0.9383 \t 0.9009 \t 0.9537 \t 0.9736\n",
      "89 \t 172.4060 \t 6.9497 \t 0.8590 \t 0.9141 \t 0.9383 \t 0.9009 \t 0.9537 \t 0.9736\n",
      "90 \t 174.3400 \t 6.9459 \t 0.8590 \t 0.9141 \t 0.9383 \t 0.9009 \t 0.9537 \t 0.9736\n",
      "91 \t 176.1651 \t 6.9422 \t 0.8590 \t 0.9141 \t 0.9383 \t 0.9009 \t 0.9537 \t 0.9736\n",
      "92 \t 177.9142 \t 6.9398 \t 0.8590 \t 0.9141 \t 0.9383 \t 0.9009 \t 0.9537 \t 0.9736\n",
      "93 \t 179.6645 \t 6.9362 \t 0.8590 \t 0.9141 \t 0.9383 \t 0.9009 \t 0.9537 \t 0.9736\n",
      "94 \t 181.4488 \t 6.9265 \t 0.8590 \t 0.9141 \t 0.9383 \t 0.9009 \t 0.9537 \t 0.9736\n",
      "95 \t 183.3968 \t 6.9244 \t 0.8590 \t 0.9141 \t 0.9383 \t 0.9009 \t 0.9537 \t 0.9736\n",
      "96 \t 185.2579 \t 6.9184 \t 0.8590 \t 0.9141 \t 0.9383 \t 0.9009 \t 0.9537 \t 0.9736\n",
      "97 \t 187.2215 \t 6.9181 \t 0.8590 \t 0.9141 \t 0.9383 \t 0.9009 \t 0.9537 \t 0.9736\n",
      "98 \t 189.2870 \t 6.9166 \t 0.8590 \t 0.9141 \t 0.9383 \t 0.9031 \t 0.9537 \t 0.9736\n",
      "99 \t 191.1488 \t 6.8885 \t 0.8590 \t 0.9141 \t 0.9383 \t 0.9009 \t 0.9537 \t 0.9736\n"
     ]
    }
   ],
   "source": [
    "print('Training...')\n",
    "print('Epoch \\t Time(sec) \\t Loss_train \\t AUC_dev \\t AUC2_dev \\t AUC3_dev \\t AUC_test \\t AUC2_test \\t AUC3_test')\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "for epoch in range(iteration):\n",
    "    if (epoch+1) % decay_interval == 0:\n",
    "        trainer.optimizer.param_groups[0]['lr'] *= lr_decay\n",
    "\n",
    "    loss = trainer.train(dataset_train)\n",
    "    auc_dev, auc2_dev, auc3_dev, _, _, _ = tester.test(dataset_dev)\n",
    "    auc_test, auc2_test, auc3_test, gcn_nplist1, gcn_nplist2, gcn_nplist3 = tester.test(dataset_test)\n",
    "    \n",
    "    lr_rate = trainer.optimizer.param_groups[0]['lr']\n",
    "\n",
    "    end = timeit.default_timer()\n",
    "    time = end - start\n",
    "\n",
    "    tester.result(epoch, time, loss, auc_dev, auc_test, file_result)\n",
    "    tester.save_model(model, file_model)\n",
    "\n",
    "    print('%d \\t %.4f \\t %.4f \\t %.4f \\t %.4f \\t %.4f \\t %.4f \\t %.4f \\t %.4f' %(epoch, time, loss, auc_dev, auc2_dev, auc3_dev, auc_test, auc2_test, auc3_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e3df6e",
   "metadata": {},
   "source": [
    "# Let's use Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9aa542d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_input = ('input'+str(radius)+'/')\n",
    "\n",
    "molecules    = load_tensor(dir_input + 'molecules', torch.LongTensor)\n",
    "adjacencies  = load_numpy(dir_input + 'adjacencies')\n",
    "t_properties = load_tensor(dir_input + 'properties', torch.LongTensor)\n",
    "maccs        = load_numpy(dir_input + 'maccs')\n",
    "\n",
    "with open(dir_input + 'fingerprint_dict.pickle', 'rb') as f:\n",
    "    fingerprint_dict = pickle.load(f)\n",
    "    \n",
    "dataset = list(zip(molecules, adjacencies, t_properties, maccs))\n",
    "dataset = shuffle_dataset(dataset, 1234)\n",
    "dataset_train, dataset_   = split_dataset(dataset, 0.8)\n",
    "dataset_dev, dataset_test = split_dataset(dataset_, 0.5)\n",
    "\n",
    "data_batch = list(zip(*dataset_train))\n",
    "properties_train, maccs_train = data_batch[-2], data_batch[-1]\n",
    "\n",
    "data_batch = list(zip(*dataset_dev))\n",
    "properties_dev, maccs_dev = data_batch[-2], data_batch[-1]\n",
    "\n",
    "data_batch = list(zip(*dataset_test))\n",
    "properties_test, maccs_test = data_batch[-2], data_batch[-1]\n",
    "\n",
    "train_len, dev_len, test_len = len(dataset_train), len(dataset_dev), len(dataset_test)\n",
    "\n",
    "feature_len = maccs_train[0].shape[0]\n",
    "\n",
    "X_train, X_dev, X_test = np.zeros((train_len,feature_len)), np.zeros((dev_len,feature_len)), np.zeros((test_len,feature_len))\n",
    "Y_train, Y_dev, Y_test = np.zeros((train_len,)), np.zeros((dev_len,)), np.zeros((test_len,))\n",
    "\n",
    "for i in range(train_len):\n",
    "    X_train[i,:] = maccs_train[i]\n",
    "    Y_train[i] = properties_train[i][0]\n",
    "    \n",
    "for i in range(dev_len):\n",
    "    X_dev[i,:]   = maccs_dev[i]\n",
    "    Y_dev[i]   = properties_dev[i][0]\n",
    "    \n",
    "for i in range(test_len):\n",
    "    X_test[i,:]  = maccs_test[i]\n",
    "    Y_test[i]  = properties_test[i][0]\n",
    "\n",
    "fingerprint_dict = load_pickle(dir_input + 'fingerprint_dict.pickle')\n",
    "unknown          = 100\n",
    "n_fingerprint    = len(fingerprint_dict) + unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5064c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples : 454, Top-1 Correct : 398, Top-1 Incorrect : 56\n",
      "Prediction Accuracy Top-1 : 87.67%\n",
      "Total samples : 454, Top-2 Correct : 433, Top-2 Incorrect : 21\n",
      "Prediction Accuracy Top-2 : 95.37%\n",
      "Total samples : 454, Top-3 Correct : 440, Top-3 Incorrect : 14\n",
      "Prediction Accuracy Top-3 : 96.92%\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=300, criterion = 'gini', max_depth=60, random_state=0)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "rf_neg_pos_list1 = []\n",
    "rf_neg_pos_list2 = []\n",
    "rf_neg_pos_list3 = []\n",
    "\n",
    "Y_pred = clf.predict_proba(X_test)\n",
    "\n",
    "num_classes = 3\n",
    "top_n = np.argsort(Y_pred)[:,:-num_classes-1:-1]\n",
    "top_n = clf.classes_[top_n]\n",
    "\n",
    "TP1 = 0\n",
    "TP2 = 0\n",
    "TP3 = 0\n",
    "\n",
    "FN1 = 0\n",
    "FN2 = 0\n",
    "FN3 = 0\n",
    "\n",
    "for i in range(X_test.shape[0]):\n",
    "    true_class = Y_test[i]\n",
    "    \n",
    "    if true_class in top_n[i,0:1]:\n",
    "        TP1 += 1\n",
    "        rf_neg_pos_list1.append(1)\n",
    "    else:\n",
    "        FN1 += 1\n",
    "        rf_neg_pos_list1.append(0)\n",
    "    \n",
    "    if true_class in top_n[i,0:2]:\n",
    "        TP2 += 1\n",
    "        rf_neg_pos_list2.append(1)\n",
    "    else:\n",
    "        FN2 += 1\n",
    "        rf_neg_pos_list2.append(0)\n",
    "        \n",
    "    if true_class in top_n[i,0:3]:\n",
    "        TP3 += 1\n",
    "        rf_neg_pos_list3.append(1)\n",
    "    else:\n",
    "        FN3 += 1\n",
    "        rf_neg_pos_list3.append(0)\n",
    "print('Total samples : %d, Top-1 Correct : %d, Top-1 Incorrect : %d' %(TP1+FN1, TP1, FN1))\n",
    "print('Prediction Accuracy Top-1 : %.2f%%' %(100.0*TP1/(TP1+FN1)))\n",
    "        \n",
    "print('Total samples : %d, Top-2 Correct : %d, Top-2 Incorrect : %d' %(TP2+FN2, TP2, FN2))\n",
    "print('Prediction Accuracy Top-2 : %.2f%%' %(100.0*TP2/(TP2+FN2)))\n",
    "\n",
    "print('Total samples : %d, Top-3 Correct : %d, Top-3 Incorrect : %d' %(TP3+FN3, TP3, FN3))\n",
    "print('Prediction Accuracy Top-3 : %.2f%%' %(100.0*TP3/(TP3+FN3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
